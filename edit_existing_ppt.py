from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
from pptx.dml.color import RGBColor
import os
import copy

SOURCE_PPTX = "/Users/ashishb/Documents/cap/ppt/NYC-Citi-Bike-Demand-A-Big-Data-Exploratory-Analysis-and-Advanced-Interactive-Dashboard.pptx"
OUTPUT_PPTX = "/Users/ashishb/Documents/cap/NYC_Citi_Bike_Final_Edited.pptx"

# Image Paths
IMAGES = {
    "architecture": "/Users/ashishb/.gemini/antigravity/brain/47521311-833e-4118-b37a-190fd352baf3/architecture_diagram_1765490065515.png",
    "map": "/Users/ashishb/.gemini/antigravity/brain/47521311-833e-4118-b37a-190fd352baf3/map_3d_viz_1765490079894.png",
    "station": "/Users/ashishb/.gemini/antigravity/brain/47521311-833e-4118-b37a-190fd352baf3/station_analytics_ui_1765490093801.png",
    "neural": "/Users/ashishb/.gemini/antigravity/brain/47521311-833e-4118-b37a-190fd352baf3/neural_network_ai_1765490107079.png",
    "route": "/Users/ashishb/.gemini/antigravity/brain/47521311-833e-4118-b37a-190fd352baf3/route_network_flow_1765490121023.png",
    "fleet": "/Users/ashishb/.gemini/antigravity/brain/47521311-833e-4118-b37a-190fd352baf3/fleet_command_dashboard_1765490136464.png"
}

CONTENT = [
    {
        "title": "NYC Citi Bike Analytics",
        "subtitle": "A Big Data Exploratory Analysis & Advanced Interactive Dashboard\nGenerated by Antigravity",
        "image": None
    },
    {
        "title": "Executive Summary",
        "bullets": [
            "Objective: Revolutionize urban mobility analysis using Big Data & AI.",
            "Scope: COMPREHENSIVE dashboard for NYC Citi Bike system (millions of trips).",
            "Key Innovation: Real-time geospatial visualization + Neural Demand forecasting.",
            "Impact: Enables data-driven decisions for fleet rebalancing and planning.",
            "Target Audience: City planners, operations managers, and data scientists."
        ],
        "image": None
    },
    {
        "title": "System Architecture Overview",
        "bullets": [
             "Modern Full-Stack Application:",
             "- Frontend: React 18, Vite, Tailwind CSS (Glassmorphism Design).",
             "- Visualization: Deck.gl (3D Hexagon/Heatmaps), Recharts, MapLibre.",
             "- Backend: FastAPI (Python) for high-performance REST endpoints.",
             "- Data Layer: Optimized data loading, Pandas/NumPy processing.",
             "- AI Layer: PyTorch/TensorFlow based LSTM & CNN models."
        ],
        "image": IMAGES["architecture"]
    },
    {
        "title": "Data Pipeline & Methodology",
        "bullets": [
             "Scale: Handling massive historical trip datasets (CSV/Parquet).",
             "Preprocessing steps:",
             "- Cleaning null values & anomalies.",
             "- Spatial aggregation (Hexagon binning).",
             "- Temporal aggregation (Hourly traffic patterns).",
             "Optimization: Efficient filtering by trip duration, distance, and user type.",
             "Result: High-speed query performance for the interactive dashboard."
        ],
        "image": None
    },
    {
        "title": "Map Explorer: 3D Geospatial Intelligence",
        "bullets": [
             "Core Feature: Advanced 3D visualization of station activity.",
             "Modes:",
             "- 3D Hex Density: Aggregated trip volume visualization.",
             "- Heatmaps: Identification of high-activity hot zones.",
             "- Points: Individual station status with rich tooltips.",
             "Interactivity: Tilt, zoom, and dynamic tooltips showing station details.",
             "Tech: High-performance WebGL rendering via Deck.gl."
        ],
        "image": IMAGES["map"]
    },
    {
        "title": "Station Intel: Deep Dive Analytics",
        "bullets": [
             "Detailed Profile: Granular analysis of individual stations.",
             "Metrics:",
             "- Inbound vs. Outbound trip distribution.",
             "- Peak hour identification.",
             "- Connectivity rankings (top sourced/destined connections).",
             "Visualization: Radar charts for temporal patterns.",
             "Utility: Pinpoints operational bottlenecks at specific locations."
        ],
        "image": IMAGES["station"]
    },
    {
        "title": "Neural Demand Lab: AI Forecasting",
        "bullets": [
             "Goal: Predict future bike availability and demand.",
             "Models:",
             "- CNN (Convolutional Neural Networks) for spatial patterns.",
             "- LSTM (Long Short-Term Memory) for temporal sequences.",
             "Features: Training on historical usage, weather correlation.",
             "Output: Accurate demand forecasts to preempt stockouts or overflows."
        ],
        "image": IMAGES["neural"]
    },
    {
        "title": "Route Explorer: Network Flow",
        "bullets": [
             "Visualization: Tracing popular travel corridors.",
             "Insights:",
             "- Identification of major commuter arteries.",
             "- Cross-borough traffic analysis.",
             "- Usage duration vs. distance correlation.",
             "Application: Helps in planning new bike lane infrastructure."
        ],
        "image": IMAGES["route"]
    },
    {
        "title": "Fleet Command: Strategic Rebalancing",
        "bullets": [
             "Operational Dashboard: Specialized view for logistics teams.",
             "Critical Alerts: identifying stations with <10% ('Red Zone') availability.",
             "Optimization: Suggestions for moving bikes from overflow to empty stations.",
             "Efficiency: Maximizes fleet utilization and reduces lost revenue."
        ],
        "image": IMAGES["fleet"]
    },
    {
        "title": "UX Design Philosophy",
        "bullets": [
             "Aesthetics: 'Glassmorphism' style with deep dark mode.",
             "Responsiveness: Fluid animations and transitions.",
             "Clarity: High-contrast data visualizations for readability.",
             "Feedback: Rich interactive elements (pulsing markers, hover effects).",
             "Goal: To provide an enterprise-grade, polished analytical tool."
        ],
        "image": None
    },
    {
        "title": "Technical Challenges Solved",
        "bullets": [
             "Challenge 1: Rendering 2000+ interactive 3D objects smoothy via WebGL.",
             "Challenge 2: Large dataset latency solved by backend pre-aggregation.",
             "Challenge 3: Complex layout management with modular architecture."
        ],
        "image": None
    },
     {
        "title": "Future Roadmap & Conclusion",
        "bullets": [
             "Real-Time Integration: Live feed from Citi Bike GBMFS API.",
             "Weather API: dynamic model adjustment based on live rain/snow data.",
             "Mobile App: Companion app for field rebalancing teams.",
             "Conclusion: A scalable, robust platform for modern urban mobility."
        ],
        "image": None
    }
]

def edit_presentation():
    if not os.path.exists(SOURCE_PPTX):
        print(f"Error: {SOURCE_PPTX} not found.")
        return

    prs = Presentation(SOURCE_PPTX)
    
    # We need 12 slides. If we have fewer, we must duplicate the last one (layout wise) or add new ones.
    # The source has 10 slides. We need 2 more.
    # A robust way to 'duplicate' is tricky in python-pptx without deep copying XML.
    # Instead, we will add 2 new slides using the last slide's layout.
    
    current_count = len(prs.slides)
    target_count = len(CONTENT)
    
    if current_count < target_count:
        last_layout = prs.slides[-1].slide_layout
        for _ in range(target_count - current_count):
            prs.slides.add_slide(last_layout)
    
    # Now iterate and replace content
    for i, slide_data in enumerate(CONTENT):
        if i >= len(prs.slides): break
        
        slide = prs.slides[i]
        
        # CLEAR EXISTING TEXT first
        # We try to identify Title vs Body shapes based on position or assumption
        # Layout analysis showed multiple text boxes.
        # Usually checking `shape.name` or position is good.
        # 'Text 0' seemed to be Title in inspection. 'Text 1' seemed to be Body.
        
        # Sort shapes by top position to guess title (top) vs content (below)
        text_shapes = [s for s in slide.shapes if s.has_text_frame]
        text_shapes.sort(key=lambda x: x.top)
        
        # Title replacement
        if text_shapes:
            title_shape = text_shapes[0]
            title_shape.text_frame.text = slide_data['title']
            # Re-apply some formatting if lost? 
            # Ideally we keep the frame's style. `text_frame.text = ...` keeps paragraph properties sometimes but resets runs.
            # To be safe and keep format:
            p = title_shape.text_frame.paragraphs[0]
            p.text = slide_data['title']
            # Clear other paragraphs in title if any
            for _ in range(len(title_shape.text_frame.paragraphs) - 1):
                # This is hard to delete paragraphs easily. 
                # Just setting text is safer.
                pass
            
            # Content replacement
            # If we have bullets, we look for the next text shape
            if 'bullets' in slide_data and len(text_shapes) > 1:
                body_shape = text_shapes[1]
                tf = body_shape.text_frame
                tf.clear() # Clear existing text
                
                # Add new bullets
                first = True
                for bullet in slide_data['bullets']:
                     p = tf.add_paragraph() if not first else tf.paragraphs[0]
                     p.text = bullet
                     p.font.size = Pt(18) # Enforce size
                     p.space_after = Pt(10)
                     if bullet.startswith("-"):
                         p.level = 1
                         p.text = bullet[1:].strip()
                     else:
                         p.level = 0
                     first = False
                     
            # Subtitle for Slide 1
            if 'subtitle' in slide_data and len(text_shapes) > 1:
                 # Usually the second box on title slide
                 body_shape = text_shapes[1]
                 body_shape.text_frame.text = slide_data['subtitle']
        
        # Image Replacement / Addition
        if slide_data['image'] and os.path.exists(slide_data['image']):
             # If there is an existing image (Picture), replace it? 
             # Or just add new one on top/side?
             # Inspection showed 'Image 0' on slides.
             images = [s for s in slide.shapes if s.shape_type == 13] # PICTURE
             if images:
                 # Replace the FIRST image found with ours
                 # python-pptx doesn't support "replace image blob" easily on a shape.
                 # Easiest is to deleting the old pic and adding new one in same spot.
                 old_pic = images[0]
                 left, top, width, height = old_pic.left, old_pic.top, old_pic.width, old_pic.height
                 
                 # Delete old pic? python-pptx requires deleting from spTree.
                 # Accessible via `old_pic._element.getparent().remove(old_pic._element)`
                 old_pic._element.getparent().remove(old_pic._element)
                 
                 # Add new pic
                 slide.shapes.add_picture(slide_data['image'], left, top, width=width, height=height)
             else:
                 # No image placeholder found, add to right side
                 slide.shapes.add_picture(slide_data['image'], Inches(6), Inches(2), width=Inches(3.5))

    prs.save(OUTPUT_PPTX)
    print(f"Saved edited presentation to {OUTPUT_PPTX}")

if __name__ == "__main__":
    edit_presentation()
